{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Sentiment Analysis\n",
    "\n",
    "In this lab we use part of the 'Amazon_Unlocked_Mobile.csv' dataset published by Kaggle. The dataset contain the following information:\n",
    "* Product Name\n",
    "* Brand Name\n",
    "* Price\n",
    "* Rating\n",
    "* Reviews\n",
    "* Review Votes\n",
    "\n",
    "We are mainly interested by the 'Reviews' (X) and by the 'Rating' (y)\n",
    "\n",
    "The goal is to try to predict the 'Rating' after reading the 'Reviews'. I've prepared for you TRAIN and TEST set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T09:18:42.942697Z",
     "start_time": "2019-11-27T09:18:42.939919Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T09:18:43.137676Z",
     "start_time": "2019-11-27T09:18:43.079350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       Product Name Brand Name  \\\n",
       "0           0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "1           1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "2           2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "3           3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "4           4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "\n",
       "    Price  Rating                                            Reviews  \\\n",
       "0  199.99       5  I feel so LUCKY to have found this used (phone...   \n",
       "1  199.99       4  nice phone, nice up grade from my pantach revu...   \n",
       "2  199.99       5                                       Very pleased   \n",
       "3  199.99       4  It works good but it goes slow sometimes but i...   \n",
       "4  199.99       4  Great phone to replace my lost phone. The only...   \n",
       "\n",
       "   Review Votes  \n",
       "0           1.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN = pd.read_csv('dataset/TRAIN.csv.gz')\n",
    "display(TRAIN.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T09:18:43.278128Z",
     "start_time": "2019-11-27T09:18:43.240425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13320</td>\n",
       "      <td>Apple iPhone 4S 16GB Unlocked GSM - White (Cer...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>129.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Very nice well taken care of phone.... Works g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13321</td>\n",
       "      <td>Apple iPhone 4S 16GB Unlocked GSM - White (Cer...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>129.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as described. Perfect.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13322</td>\n",
       "      <td>Apple iPhone 4S 16GB Unlocked GSM - White (Cer...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>129.99</td>\n",
       "      <td>4</td>\n",
       "      <td>phone is good work in Ukraine, but charge incl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13323</td>\n",
       "      <td>Apple iPhone 4S 16GB Unlocked GSM - White (Cer...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>129.99</td>\n",
       "      <td>3</td>\n",
       "      <td>At the moment I have to say its ok,because I h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13324</td>\n",
       "      <td>Apple iPhone 4S 16GB Unlocked GSM - White (Cer...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>129.99</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone is flawless. But the battery doesn't st...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       Product Name Brand Name  \\\n",
       "0       13320  Apple iPhone 4S 16GB Unlocked GSM - White (Cer...      Apple   \n",
       "1       13321  Apple iPhone 4S 16GB Unlocked GSM - White (Cer...      Apple   \n",
       "2       13322  Apple iPhone 4S 16GB Unlocked GSM - White (Cer...      Apple   \n",
       "3       13323  Apple iPhone 4S 16GB Unlocked GSM - White (Cer...      Apple   \n",
       "4       13324  Apple iPhone 4S 16GB Unlocked GSM - White (Cer...      Apple   \n",
       "\n",
       "    Price  Rating                                            Reviews  \\\n",
       "0  129.99       4  Very nice well taken care of phone.... Works g...   \n",
       "1  129.99       5                     Exactly as described. Perfect.   \n",
       "2  129.99       4  phone is good work in Ukraine, but charge incl...   \n",
       "3  129.99       3  At the moment I have to say its ok,because I h...   \n",
       "4  129.99       3  iPhone is flawless. But the battery doesn't st...   \n",
       "\n",
       "   Review Votes  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           1.0  \n",
       "3           1.0  \n",
       "4           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEST = pd.read_csv('dataset/TEST.csv.gz')\n",
    "display(TEST.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build X (features vectors) and y (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.  Construct X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = TRAIN['Reviews']\n",
    "y_train = TRAIN['Rating']\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = TEST['Reviews']\n",
    "y_test = TEST['Rating']\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T09:18:43.717593Z",
     "start_time": "2019-11-27T09:18:43.713460Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "X_train =  \"\".join(TRAIN['Reviews'])\n",
    "y_train = TRAIN['Rating']\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "X_train = tokenizer.tokenize(X_train)\n",
    "y_train = TRAIN['Rating']\n",
    "for i in range(0,len(X_train)-1):\n",
    "    X_train[i] = X_train[i].split()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b.  Construct X_test and y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T09:18:44.018565Z",
     "start_time": "2019-11-27T09:18:44.014846Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test =  \"\".join(TEST['Reviews']+\" \")\n",
    "X_test = tokenizer.tokenize(X_test)\n",
    "y_test = TEST['Rating']\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax =plt.subplots(1,2,figsize=(12, 3), sharex=True, sharey=True)\n",
    "\n",
    "sns.countplot(x='Rating',data=TRAIN,palette='rainbow',ax=ax[0]).set_title('Ratings for training dataset')\n",
    "sns.countplot(x='Rating',data=TEST,palette='rainbow',ax=ax[1]).set_title('Ratings for test dataset')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construct a Baseline\n",
    "Using CountVectorizer and a classifier, learned in a previous lecture, build a first model.\n",
    "\n",
    "For this model, you will not pre-process the text and will only use words (not N-grams).\n",
    "\n",
    "The evaluation metric is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(X_train)\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A better classifier with a preprocessing\n",
    "By always using words and the same classification but pre-processing the text with one or more notebook techniques \"text-preprocessing\" try to get a better model.\n",
    "\n",
    "The evaluation metric is always accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T09:18:44.623197Z",
     "start_time": "2019-11-27T09:18:44.619913Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    for i in range(len(mess)-1):\n",
    "    # Check characters to see if they are in punctuation\n",
    "        nopunc = [char for char in mess[i] if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "        nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "        return nopunc\n",
    "    #[word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "X_train.apply(text_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the battery was old & had been over used because it barely holds a charge. otherwise, no issues with the phone itself.\n",
      "this phone looks like new and works perfectly. just inserted the sim card from my old phone, went through the easy setup prompts and done!\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.apply(lambda x: str.lower(x))\n",
    "X_test = X_test.apply(lambda x: str.lower(x))\n",
    "\n",
    "print(X_train[20])\n",
    "print(X_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the battery was old had been over used because it barely holds a charge otherwise no issues with the phone itself\n",
      "this phone looks like new and works perfectly just inserted the sim card from my old phone went through the easy setup prompts and done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "X_train = X_train.apply(lambda x : \" \".join(re.findall('[\\w]+',x)))\n",
    "X_test = X_test.apply(lambda x : \" \".join(re.findall('[\\w]+',x)))\n",
    "\n",
    "print(X_train[20])\n",
    "print(X_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery old used barely holds charge otherwise issues phone\n",
      "phone looks like new works perfectly inserted sim card old phone went easy setup prompts done\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def remove_stopWords(s):\n",
    "    '''For removing stop words\n",
    "    '''\n",
    "    s = ' '.join(word for word in s.split() if word not in stopwords.words('english'))\n",
    "    return s\n",
    "\n",
    "X_train = X_train.apply(lambda x: remove_stopWords(x))\n",
    "X_test = X_test.apply(lambda x: remove_stopWords(x))\n",
    "\n",
    "print(X_train[20])\n",
    "print(X_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(X_train)\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10342)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 887)\t1\n",
      "  (0, 930)\t1\n",
      "  (0, 3675)\t1\n",
      "  (0, 3683)\t1\n",
      "  (0, 3731)\t1\n",
      "  (0, 3892)\t1\n",
      "  (0, 4381)\t1\n",
      "  (0, 4495)\t1\n",
      "  (0, 4551)\t1\n",
      "  (0, 5438)\t1\n",
      "  (0, 5453)\t1\n",
      "  (0, 5605)\t1\n",
      "  (0, 6355)\t1\n",
      "  (0, 6364)\t2\n",
      "  (0, 6751)\t3\n",
      "  (0, 7385)\t1\n",
      "  (0, 7453)\t1\n",
      "  (0, 7919)\t1\n",
      "  (0, 8106)\t2\n",
      "  (0, 8500)\t1\n",
      "  (0, 8517)\t1\n",
      "  (0, 8526)\t1\n",
      "  (0, 9199)\t1\n",
      "  (0, 9752)\t1\n",
      "  (0, 9754)\t1\n",
      "  :\t:\n",
      "  (9998, 7947)\t1\n",
      "  (9999, 913)\t1\n",
      "  (9999, 977)\t1\n",
      "  (9999, 1524)\t1\n",
      "  (9999, 1544)\t1\n",
      "  (9999, 1692)\t1\n",
      "  (9999, 1766)\t1\n",
      "  (9999, 1893)\t1\n",
      "  (9999, 1898)\t1\n",
      "  (9999, 3865)\t1\n",
      "  (9999, 4911)\t1\n",
      "  (9999, 5437)\t1\n",
      "  (9999, 5551)\t1\n",
      "  (9999, 6164)\t1\n",
      "  (9999, 6186)\t1\n",
      "  (9999, 6539)\t1\n",
      "  (9999, 6751)\t3\n",
      "  (9999, 7084)\t1\n",
      "  (9999, 7174)\t1\n",
      "  (9999, 7191)\t1\n",
      "  (9999, 7440)\t1\n",
      "  (9999, 8009)\t1\n",
      "  (9999, 8017)\t1\n",
      "  (9999, 8319)\t1\n",
      "  (9999, 10165)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X_transformer = CountVectorizer(analyzer=text_process).fit(X_train)\n",
    "#X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = X_transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_transformer.get_feature_names()[2549])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10276)\t0.16161994903310473\n",
      "  (0, 10224)\t0.10021757451082593\n",
      "  (0, 9996)\t0.13672784393996923\n",
      "  (0, 9799)\t0.34408866480251593\n",
      "  (0, 9777)\t0.16750089401734622\n",
      "  (0, 9754)\t0.19861238996161037\n",
      "  (0, 9752)\t0.16825692374376866\n",
      "  (0, 9199)\t0.13814917281714342\n",
      "  (0, 8526)\t0.1568519762158024\n",
      "  (0, 8517)\t0.16700688851400694\n",
      "  (0, 8500)\t0.16533712522250962\n",
      "  (0, 8106)\t0.2438086575403722\n",
      "  (0, 7919)\t0.1342367793446165\n",
      "  (0, 7453)\t0.12575746037194296\n",
      "  (0, 7385)\t0.1166257728355801\n",
      "  (0, 6751)\t0.15580294920785784\n",
      "  (0, 6364)\t0.19442981783350388\n",
      "  (0, 6355)\t0.13795586975312746\n",
      "  (0, 5605)\t0.22453393219319448\n",
      "  (0, 5453)\t0.1767040220142858\n",
      "  (0, 5438)\t0.18139010432810335\n",
      "  (0, 4551)\t0.24313963194598473\n",
      "  (0, 4495)\t0.16161994903310473\n",
      "  (0, 4381)\t0.15981819039555778\n",
      "  (0, 3892)\t0.15150370523428736\n",
      "  :\t:\n",
      "  (9998, 21)\t0.7326834829949377\n",
      "  (9999, 10165)\t0.18051471233754432\n",
      "  (9999, 8319)\t0.15416642138736006\n",
      "  (9999, 8017)\t0.13023317392857917\n",
      "  (9999, 8009)\t0.17875287508448678\n",
      "  (9999, 7440)\t0.3096487561360767\n",
      "  (9999, 7191)\t0.25043731859913143\n",
      "  (9999, 7174)\t0.2217694504021475\n",
      "  (9999, 7084)\t0.1666282061426153\n",
      "  (9999, 6751)\t0.1984217424301412\n",
      "  (9999, 6539)\t0.290129543229333\n",
      "  (9999, 6186)\t0.2740590098924012\n",
      "  (9999, 6164)\t0.11451495235150655\n",
      "  (9999, 5551)\t0.19449339142724864\n",
      "  (9999, 5437)\t0.12001770874359433\n",
      "  (9999, 4911)\t0.2363005742470463\n",
      "  (9999, 3865)\t0.3062000765662648\n",
      "  (9999, 1898)\t0.20113247891632755\n",
      "  (9999, 1893)\t0.16150692345577514\n",
      "  (9999, 1766)\t0.15416642138736006\n",
      "  (9999, 1692)\t0.215603696240778\n",
      "  (9999, 1544)\t0.16416797710230158\n",
      "  (9999, 1524)\t0.1716150650546436\n",
      "  (9999, 977)\t0.1697762856526741\n",
      "  (9999, 913)\t0.15352998789461242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_train_tfidf.shape\n",
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6702"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. A better classifier using Ngrams\n",
    "Starting from the previous work but bi or tri-fat try to get a better classification.\n",
    "\n",
    "The evaluation metric is always accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "X_train_cv1 = cv.fit_transform(X_train)\n",
    "X_test_cv1 = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 101848)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf1 = tfidf_transformer.fit_transform(X_train_cv1)\n",
    "X_train_tfidf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_tfidf1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = nb.predict(X_test_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.653"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (Optional) A better classifier by combining many classifier\n",
    "\n",
    "The goal of [ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html) is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "\n",
    "I proposed to use **averaging methods**. In this family, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(base_estimator = nb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                               fit_prior=True),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=10, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6704"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0 Accuracy is: 0.6007984031936128\n",
      "Model: 1 Accuracy is: 0.624750499001996\n",
      "Model: 2 Accuracy is: 0.6453546453546454\n",
      "Model: 3 Accuracy is: 0.6283716283716284\n",
      "Model: 4 Accuracy is: 0.6303696303696303\n",
      "Model: 5 Accuracy is: 0.6433566433566433\n",
      "Model: 6 Accuracy is: 0.6266266266266266\n",
      "Model: 7 Accuracy is: 0.6202404809619239\n",
      "Model: 8 Accuracy is: 0.6392785571142284\n",
      "Model: 9 Accuracy is: 0.6148445336008024\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "results = model_selection.cross_val_score(model, X_train_tfidf,y_train,cv=10)\n",
    "for i in range(len(results)):\n",
    "    print(\"Model: \"+str(i)+\" Accuracy is: \"+str(results[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summarize your conclusion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T09:18:45.515929Z",
     "start_time": "2019-11-27T09:18:45.511826Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to lack of time, I could not analyze the results very well. \n",
    "\n",
    "However, without doing any preprocessing, the model gives 0.66 accuracy score which is quite low.\n",
    "Then I did some text preprocessing which considers removing punctuations and stopwords. Somehow it gives a worse accuracy score than the first model. Even when I applied n-grams, weirdly it did not improve the score.\n",
    "\n",
    "I'm guessing that I could have done a mistake by doing count vectorizer at the beginning. I will continue to work on to improve accuracy score.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
